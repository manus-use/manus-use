# ManusUse Configuration Example
# Copy this file to config.toml and update with your settings

[llm]
# Provider options: openai, anthropic, bedrock, ollama, litellm
provider = "openai"

# Model name
model = "gpt-4o"

# API key (can also use environment variables)
api_key = "sk-..."

# Optional: API base URL for custom endpoints
# base_url = "https://api.openai.com/v1"

# Model parameters
temperature = 0.0
max_tokens = 4096

[sandbox]
# Enable Docker sandbox for secure code execution
enabled = true

# Docker image to use for sandbox
docker_image = "python:3.12-slim"

# Execution timeout in seconds
timeout = 300

# Resource limits
memory_limit = "512m"
cpu_limit = 1.0

[tools]
# Enabled tool categories
enabled = ["file_ops", "code_execute", "web_search", "browser", "visualization"]

# Browser settings
browser_headless = true

# Search engine: duckduckgo, google
search_engine = "duckduckgo"
max_search_results = 5

# Optional: Google Custom Search credentials
# google_api_key = "..."
# google_cx = "..."

[browser_use]
# Browser-use specific configuration
# These settings override the main LLM config when using browser-use agent

[otx]
api_key = "..." # AlienVault OTX API key

[github]
# GitHub API token for authenticated access (higher rate limits)
# Can also use GITHUB_TOKEN environment variable
api_token = "ghp_..."
# DO NOT commit real tokens to version control!

# LLM settings for browser-use (optional - defaults to main LLM config)
# provider = "bedrock"  # or "openai"
# model = "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
# api_key = "..."  # Optional, defaults to main LLM api_key or env vars
temperature = 0.0
max_tokens = 4096

# Browser settings
headless = true  # Run browser in headless mode
keep_alive = false  # Keep browser open between tasks
disable_security = false  # Disable browser security features (use with caution)
extra_chromium_args = []  # Additional Chrome/Chromium args, e.g. ["--no-sandbox"]

# Agent settings
max_steps = 100  # Maximum steps per task
max_actions_per_step = 10  # Maximum actions in a single step
use_vision = true  # Use vision capabilities for browser automation
save_conversation_path = ""  # Optional: Path to save conversation history
max_error_length = 400  # Maximum error message length in logs
tool_calling_method = "auto"  # Options: "auto", "function_calling", "json_mode"

# Memory and context
enable_memory = false  # Enable conversation memory between tasks
memory_window = 10  # Number of previous messages to keep in memory

# Performance settings
timeout = 300  # Task timeout in seconds
retry_count = 3  # Number of retries on failure

# Debugging
debug = false  # Enable debug logging
save_screenshots = false  # Save screenshots during execution
screenshot_path = ""  # Optional: Path to save screenshots

[mcp]
# MCP SSE server URL for agent communication
server_url = "https://your-mcp-server.example.com/sse?_g_auth=YOUR_TOKEN_HERE"
# DO NOT commit real tokens to version control!

[webhooks]
# Webhook URL for CVE submission (do not commit real tokens)
cve_submit_url = "https://your-webhook.example.com/path/to/webhook"
# DO NOT commit real tokens to version control!

[lark]
# Lark document creation API URL and token (do not commit real tokens)
document_url = "https://your-lark-api.example.com/path/to/endpoint"
api_token = "your-lark-api-token"
# DO NOT commit real tokens to version control!